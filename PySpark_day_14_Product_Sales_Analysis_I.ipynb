{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74Ing74bzJGz",
        "outputId": "c7ff2213-45a3-4f02-ba03-5a6e477aa2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=11f670ac37c1bf3ed653489eec23f366d77c5c3831b5e355762c56fd59888dfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "# ps-42\n",
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸŒŸ ğğ˜ğ’ğğ€ğ‘ğŠ ğğ«ğšğœğ­ğ¢ğœğ/ğˆğ§ğ­ğğ«ğ¯ğ¢ğğ° ğğ«ğ¨ğ›ğ¥ğğ¦ ğŸ“Š\n",
        "========================================\n",
        "\n",
        "Write an pyspark code that reports all product names of\n",
        "the products in the Sales table along with their selling\n",
        "year and price.\n",
        "\n",
        "ğ’ğœğ¡ğğ¦ğš ğ€ğ§ğ ğƒğšğ­ğš:\n",
        "================\n",
        " # Define the schema for the DataFrame\n",
        "schema = StructType([\n",
        " StructField(\"sale_id\", IntegerType()),\n",
        " StructField(\"product_id\", IntegerType()),\n",
        " StructField(\"year\", IntegerType(), True),\n",
        " StructField(\"quantity\", IntegerType()),\n",
        " StructField(\"price\", IntegerType())\n",
        "])\n",
        "# Provide the data as a list of tuples\n",
        "data = [\n",
        " (1, 100, 2008, 10, 5000),\n",
        " (2, 100, 2009, 12, 5000),\n",
        " (7, 200, 2011, 15, 9000)\n",
        "]\n",
        "# Define the schema for the products DataFrame\n",
        "products_schema = StructType([\n",
        " StructField(\"product_id\", IntegerType(), True),\n",
        " StructField(\"product_name\", StringType(), True),\n",
        "])\n",
        "# Provide the product data as a list of tuples\n",
        "products_data = [\n",
        " (100, \"Nokia\"),\n",
        " (200, \"Apple\"),\n",
        " (300, \"Samsung\"),\n",
        "]"
      ],
      "metadata": {
        "id": "0h9wsqYgzna7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import all necessary module\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "5ZMZAdMyzKL4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create spark session\n",
        "spark = SparkSession.builder.master('local').appName('pyspark-day-14').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "mwuSLVUBzNlP",
        "outputId": "f42e9423-f32e-4824-cf8f-415159c956a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f0ecc1a5360>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://da5150334a7e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-day-13</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema for the DataFrame\n",
        "sales_schema = StructType([\n",
        " StructField(\"sale_id\", IntegerType()),\n",
        " StructField(\"product_id\", IntegerType()),\n",
        " StructField(\"year\", IntegerType(), True),\n",
        " StructField(\"quantity\", IntegerType()),\n",
        " StructField(\"price\", IntegerType())\n",
        "])\n",
        "# Provide the data as a list of tuples\n",
        "sales_data = [\n",
        " (1, 100, 2008, 10, 5000),\n",
        " (2, 100, 2009, 12, 5000),\n",
        " (7, 200, 2011, 15, 9000)\n",
        "]"
      ],
      "metadata": {
        "id": "n4Fc7iUUzQDm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema for the products DataFrame\n",
        "products_schema = StructType([\n",
        " StructField(\"product_id\", IntegerType(), True),\n",
        " StructField(\"product_name\", StringType(), True),\n",
        "])\n",
        "# Provide the product data as a list of tuples\n",
        "products_data = [\n",
        " (100, \"Nokia\"),\n",
        " (200, \"Apple\"),\n",
        " (300, \"Samsung\"),\n",
        "]"
      ],
      "metadata": {
        "id": "KC4MyNig1bsm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sales df\n",
        "sale_df = spark.createDataFrame(schema = sales_schema, data = sales_data)\n",
        "sale_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaKLBBE11cQs",
        "outputId": "bc140b4c-39e1-494e-86cc-0954f83ed104"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+----+--------+-----+\n",
            "|sale_id|product_id|year|quantity|price|\n",
            "+-------+----------+----+--------+-----+\n",
            "|      1|       100|2008|      10| 5000|\n",
            "|      2|       100|2009|      12| 5000|\n",
            "|      7|       200|2011|      15| 9000|\n",
            "+-------+----------+----+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sale_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGiDIrzA1pW6",
        "outputId": "8f27de9d-5b69-4747-aca4-4c38f2a3c71e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sale_id: integer (nullable = true)\n",
            " |-- product_id: integer (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- quantity: integer (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create product df\n",
        "product_df = spark.createDataFrame(schema = products_schema, data = products_data)\n",
        "product_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0imQBKC10sI",
        "outputId": "ddc973be-4b2f-4202-c416-88afae75dc4a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+\n",
            "|product_id|product_name|\n",
            "+----------+------------+\n",
            "|       100|       Nokia|\n",
            "|       200|       Apple|\n",
            "|       300|     Samsung|\n",
            "+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "product_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q66p3Jg914ST",
        "outputId": "f29db7e2-f0a6-491b-bdec-6cea472cfba2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- product_id: integer (nullable = true)\n",
            " |-- product_name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# join both df\n",
        "join_df = sale_df.join(product_df, on='product_id',  how='inner')\n",
        "join_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJNZlCoG2A4l",
        "outputId": "5a3bdab1-ec51-4af7-9f0a-ff00a762629d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+----+--------+-----+------------+\n",
            "|product_id|sale_id|year|quantity|price|product_name|\n",
            "+----------+-------+----+--------+-----+------------+\n",
            "|       100|      1|2008|      10| 5000|       Nokia|\n",
            "|       100|      2|2009|      12| 5000|       Nokia|\n",
            "|       200|      7|2011|      15| 9000|       Apple|\n",
            "+----------+-------+----+--------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "join_df.select('product_name','year','price').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tG9Wcay2PrL",
        "outputId": "f1725792-02d8-4354-e3d1-c37a86e216d6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----+-----+\n",
            "|product_name|year|price|\n",
            "+------------+----+-----+\n",
            "|       Nokia|2008| 5000|\n",
            "|       Nokia|2009| 5000|\n",
            "|       Apple|2011| 9000|\n",
            "+------------+----+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}