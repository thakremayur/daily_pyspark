{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSPoNF5PZxfx",
        "outputId": "cc3e0141-9f4c-4d90-f572-ac5929000044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=2ff2aa90cd4bb3dd5688628f1734234c17d3f656cc0adc8d03413ffdfd025157\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "# ps49\n",
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌟 𝐏𝐘𝐒𝐏𝐀𝐑𝐊 𝐏𝐫𝐚𝐜𝐭𝐢𝐜𝐞/𝐈𝐧𝐭𝐞𝐫𝐯𝐢𝐞𝐰 𝐏𝐫𝐨𝐛𝐥𝐞𝐦 📊\n",
        "========================================\n",
        "\n",
        "Write an pyspark code that reports the number of posts reported yesterday for each report reason. Assume today is 2019-07-05.\n",
        "\n",
        "𝐒𝐜𝐡𝐞𝐦𝐚 𝐀𝐧𝐝 𝐃𝐚𝐭𝐚:\n",
        "================\n",
        " schema = StructType([\n",
        " StructField(\"user_id\", IntegerType(), True),\n",
        " StructField(\"post_id\", IntegerType(), True),\n",
        " StructField(\"action_date\", StringType(), True),\n",
        " StructField(\"action\", StringType(), True),\n",
        " StructField(\"extra\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Define the data\n",
        "data = [\n",
        " (1, 1, \"2019-07-01\", \"view\", None),\n",
        " (1, 1, \"2019-07-01\", \"like\", None),\n",
        " (1, 1, \"2019-07-01\", \"share\", None),\n",
        " (2, 4, \"2019-07-04\", \"view\", None),\n",
        " (2, 4, \"2019-07-04\", \"report\", \"spam\"),\n",
        " (3, 4, \"2019-07-04\", \"view\", None),\n",
        " (3, 4, \"2019-07-04\", \"report\", \"spam\"),\n",
        " (4, 3, \"2019-07-02\", \"view\", None),\n",
        " (4, 3, \"2019-07-02\", \"report\", \"spam\"),\n",
        " (5, 2, \"2019-07-04\", \"view\", None),\n",
        " (5, 2, \"2019-07-04\", \"report\", \"racism\"),\n",
        " (5, 5, \"2019-07-04\", \"view\", None),\n",
        " (5, 5, \"2019-07-04\", \"report\", \"racism\")\n",
        "]"
      ],
      "metadata": {
        "id": "FzRCOorqa6sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import all necessary module\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "YYn84ysIbB2A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create spark session\n",
        "spark = SparkSession.builder.master('local').appName('pyspark-day-7').getOrCreate()"
      ],
      "metadata": {
        "id": "1kFUzZ_KbfVO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "rIa_7drQbvt0",
        "outputId": "ebb55bf0-836e-456f-cd1b-0f021fe5bcd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a3c566d7820>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://109c4aaf4840:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-day-7</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define schema and data\n",
        "schema = StructType([\n",
        " StructField(\"user_id\", IntegerType(), True),\n",
        " StructField(\"post_id\", IntegerType(), True),\n",
        " StructField(\"action_date\", StringType(), True),\n",
        " StructField(\"action\", StringType(), True),\n",
        " StructField(\"extra\", StringType(), True)\n",
        "])\n",
        "\n",
        "data = [\n",
        " (1, 1, \"2019-07-01\", \"view\", None),\n",
        " (1, 1, \"2019-07-01\", \"like\", None),\n",
        " (1, 1, \"2019-07-01\", \"share\", None),\n",
        " (2, 4, \"2019-07-04\", \"view\", None),\n",
        " (2, 4, \"2019-07-04\", \"report\", \"spam\"),\n",
        " (3, 4, \"2019-07-04\", \"view\", None),\n",
        " (3, 4, \"2019-07-04\", \"report\", \"spam\"),\n",
        " (4, 3, \"2019-07-02\", \"view\", None),\n",
        " (4, 3, \"2019-07-02\", \"report\", \"spam\"),\n",
        " (5, 2, \"2019-07-04\", \"view\", None),\n",
        " (5, 2, \"2019-07-04\", \"report\", \"racism\"),\n",
        " (5, 5, \"2019-07-04\", \"view\", None),\n",
        " (5, 5, \"2019-07-04\", \"report\", \"racism\")\n",
        "]"
      ],
      "metadata": {
        "id": "G6ETO9MzbypY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create df\n",
        "action_df = spark.createDataFrame(schema = schema, data = data)\n",
        "action_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqLsmwmUcFHW",
        "outputId": "848ff731-fb37-49e2-db33-65690964723f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----------+------+------+\n",
            "|user_id|post_id|action_date|action| extra|\n",
            "+-------+-------+-----------+------+------+\n",
            "|      1|      1| 2019-07-01|  view|  NULL|\n",
            "|      1|      1| 2019-07-01|  like|  NULL|\n",
            "|      1|      1| 2019-07-01| share|  NULL|\n",
            "|      2|      4| 2019-07-04|  view|  NULL|\n",
            "|      2|      4| 2019-07-04|report|  spam|\n",
            "|      3|      4| 2019-07-04|  view|  NULL|\n",
            "|      3|      4| 2019-07-04|report|  spam|\n",
            "|      4|      3| 2019-07-02|  view|  NULL|\n",
            "|      4|      3| 2019-07-02|report|  spam|\n",
            "|      5|      2| 2019-07-04|  view|  NULL|\n",
            "|      5|      2| 2019-07-04|report|racism|\n",
            "|      5|      5| 2019-07-04|  view|  NULL|\n",
            "|      5|      5| 2019-07-04|report|racism|\n",
            "+-------+-------+-----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter data based on given date and action\n",
        "report_df = action_df.filter((col('action_date')=='2019-07-04') & (col('action')=='report'))\n",
        "report_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5hfI6LCcbfc",
        "outputId": "57778f89-24bb-45b7-a94e-15faeda4233b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----------+------+------+\n",
            "|user_id|post_id|action_date|action| extra|\n",
            "+-------+-------+-----------+------+------+\n",
            "|      2|      4| 2019-07-04|report|  spam|\n",
            "|      3|      4| 2019-07-04|report|  spam|\n",
            "|      5|      2| 2019-07-04|report|racism|\n",
            "|      5|      5| 2019-07-04|report|racism|\n",
            "+-------+-------+-----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group by extra then count distinct id\n",
        "report_df.groupBy('extra').agg(count_distinct('post_id').alias('report_count')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTZkNNoHfPH8",
        "outputId": "377713b4-d74d-442c-b9d5-daa8b4f47094"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+\n",
            "| extra|report_count|\n",
            "+------+------------+\n",
            "|  spam|           1|\n",
            "|racism|           2|\n",
            "+------+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}