{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pRX9-a9i5KO",
        "outputId": "d80b8edf-21a6-4a5f-af9c-380b055b689a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=405ddb30e7070e72905334c607f27b02ae985b4bfb7790f8cc4f8f1f12fa530d\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸŒŸ PYSPARK Practice/Interview Problem DAY 2ğŸ“Š\n",
        "========================================\n",
        "ğ–ğğšğ­ğ¡ğğ« ğ“ğ²ğ©ğ ğˆğ§ ğ„ğšğœğ¡ ğ‚ğ¨ğ®ğ§ğ­ğ«ğ² ğğ«ğ¨ğ›ğ¥ğğ¦\n",
        "ğ–ğ«ğ¢ğ­ğ ğšğ§ ğğ²ğ¬ğ©ğšğ«ğ¤ ğœğ¨ğğ ğ­ğ¨ ğŸğ¢ğ§ğ ğ­ğ¡ğ ğ­ğ²ğ©ğ ğ¨ğŸ ğ°ğğšğ­ğ¡ğğ« ğ¢ğ§ ğğšğœğ¡ ğœğ¨ğ®ğ§ğ­ğ«ğ² ğŸğ¨ğ« ğğ¨ğ¯ğğ¦ğ›ğğ« 2019.\n",
        "ğ“ğ¡ğ ğ­ğ²ğ©ğ ğ¨ğŸ ğ°ğğšğ­ğ¡ğğ« ğ¢ğ¬ ğ‚ğ¨ğ¥ğ ğ¢ğŸ ğ­ğ¡ğ ğšğ¯ğğ«ğšğ ğ ğ°ğğšğ­ğ¡ğğ«_ğ¬ğ­ğšğ­ğ ğ¢ğ¬ ğ¥ğğ¬ğ¬ ğ­ğ¡ğšğ§ ğ¨ğ« ğğªğ®ğšğ¥ 15,\n",
        "ğ‡ğ¨ğ­ ğ¢ğŸ ğ­ğ¡ğ ğšğ¯ğğ«ğšğ ğ ğ°ğğšğ­ğ¡ğğ«_ğ¬ğ­ğšğ­ğ ğ¢ğ¬ ğ ğ«ğğšğ­ğğ« ğ­ğ¡ğšğ§ ğ¨ğ« ğğªğ®ğšğ¥ 25 ğšğ§ğ ğ–ğšğ«ğ¦ ğ¨ğ­ğ¡ğğ«ğ°ğ¢ğ¬ğ.\n",
        "\n",
        "ğ‘ğğ­ğ®ğ«ğ§ ğ«ğğ¬ğ®ğ¥ğ­ ğ­ğšğ›ğ¥ğ ğ¢ğ§ ğšğ§ğ² ğ¨ğ«ğğğ«.\n",
        "\n",
        "\n",
        "ğ’ğœğ¡ğğ¦ğš ğ€ğ§ğ ğƒğšğ­ğš:\n",
        "================\n",
        " # Define the schema for the Weather DataFrame\n",
        "weather_schema = StructType([\n",
        " StructField(\"country_id\", IntegerType(), True),\n",
        " StructField(\"weather_state\", IntegerType(), True),\n",
        " StructField(\"day\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Weather data\n",
        "weather_data = [\n",
        " (2, 15, \"2019-11-01\"),\n",
        " (2, 12, \"2019-10-28\"),\n",
        " (2, 12, \"2019-10-27\"),\n",
        " (3, -2, \"2019-11-10\"),\n",
        " (3, 0, \"2019-11-11\"),\n",
        " (3, 3, \"2019-11-12\"),\n",
        " (5, 16, \"2019-11-07\"),\n",
        " (5, 18, \"2019-11-09\"),\n",
        " (5, 21, \"2019-11-23\"),\n",
        " (7, 25, \"2019-11-28\"),\n",
        " (7, 22, \"2019-12-01\"),\n",
        " (7, 20, \"2019-12-02\"),\n",
        " (8, 25, \"2019-11-05\"),\n",
        " (8, 27, \"2019-11-15\"),\n",
        " (8, 31, \"2019-11-25\"),\n",
        " (9, 7, \"2019-10-23\"),\n",
        " (9, 3, \"2019-12-23\")\n",
        "]\n",
        "\n",
        "# Define the schema for the Countries DataFrame\n",
        "countries_schema = StructType([\n",
        " StructField(\"country_id\", IntegerType(), True),\n",
        " StructField(\"country_name\", StringType(), True)\n",
        "])\n",
        "\n",
        "countries_data = [\n",
        " (2, \"USA\"),\n",
        " (3, \"Australia\"),\n",
        " (7, \"Peru\"),\n",
        " (5, \"China\"),\n",
        " (8, \"Morocco\"),\n",
        " (9, \"Spain\")\n",
        "]"
      ],
      "metadata": {
        "id": "bGIM_ZDYbBGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing necessary packages\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "d3VzH8IUbyvH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize spark session\n",
        "spark = SparkSession.builder.config('spark.ui.port','0').master('local').appName('PySpark-Day2').getOrCreate()"
      ],
      "metadata": {
        "id": "49jtUg7adRru"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "f3Y7S_TXdq5m",
        "outputId": "081b986e-f134-408e-b69a-4e40d0e1daa5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7b1f78ce78b0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://688aaeeab540:45573\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark-Day2</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Define the schema for the Weather DataFrame\n",
        "weather_schema = StructType([\n",
        " StructField(\"country_id\", IntegerType(), True),\n",
        " StructField(\"weather_state\", IntegerType(), True),\n",
        " StructField(\"day\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Weather data\n",
        "weather_data = [\n",
        " (2, 15, \"2019-11-01\"),\n",
        " (2, 12, \"2019-10-28\"),\n",
        " (2, 12, \"2019-10-27\"),\n",
        " (3, -2, \"2019-11-10\"),\n",
        " (3, 0, \"2019-11-11\"),\n",
        " (3, 3, \"2019-11-12\"),\n",
        " (5, 16, \"2019-11-07\"),\n",
        " (5, 18, \"2019-11-09\"),\n",
        " (5, 21, \"2019-11-23\"),\n",
        " (7, 25, \"2019-11-28\"),\n",
        " (7, 22, \"2019-12-01\"),\n",
        " (7, 20, \"2019-12-02\"),\n",
        " (8, 25, \"2019-11-05\"),\n",
        " (8, 27, \"2019-11-15\"),\n",
        " (8, 31, \"2019-11-25\"),\n",
        " (9, 7, \"2019-10-23\"),\n",
        " (9, 3, \"2019-12-23\")\n",
        "]"
      ],
      "metadata": {
        "id": "XbDakQ0Gdt9t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema for the Countries DataFrame\n",
        "countries_schema = StructType([\n",
        " StructField(\"country_id\", IntegerType(), True),\n",
        " StructField(\"country_name\", StringType(), True)\n",
        "])\n",
        "\n",
        "countries_data = [\n",
        " (2, \"USA\"),\n",
        " (3, \"Australia\"),\n",
        " (7, \"Peru\"),\n",
        " (5, \"China\"),\n",
        " (8, \"Morocco\"),\n",
        " (9, \"Spain\")\n",
        "]"
      ],
      "metadata": {
        "id": "mPyYd3F3hKdO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataframe for weather\n",
        "df_weather = spark.createDataFrame(schema = weather_schema, data = weather_data)\n",
        "df_weather.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5qT9uOUhYQA",
        "outputId": "8f361df7-00e6-4fc7-a697-526cf617720b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+----------+\n",
            "|country_id|weather_state|       day|\n",
            "+----------+-------------+----------+\n",
            "|         2|           15|2019-11-01|\n",
            "|         2|           12|2019-10-28|\n",
            "|         2|           12|2019-10-27|\n",
            "|         3|           -2|2019-11-10|\n",
            "|         3|            0|2019-11-11|\n",
            "|         3|            3|2019-11-12|\n",
            "|         5|           16|2019-11-07|\n",
            "|         5|           18|2019-11-09|\n",
            "|         5|           21|2019-11-23|\n",
            "|         7|           25|2019-11-28|\n",
            "|         7|           22|2019-12-01|\n",
            "|         7|           20|2019-12-02|\n",
            "|         8|           25|2019-11-05|\n",
            "|         8|           27|2019-11-15|\n",
            "|         8|           31|2019-11-25|\n",
            "|         9|            7|2019-10-23|\n",
            "|         9|            3|2019-12-23|\n",
            "+----------+-------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataframe for countries\n",
        "df_country = spark.createDataFrame(schema = countries_schema, data = countries_data)\n",
        "df_country.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV5TCOfyhpva",
        "outputId": "551ba468-bd23-4a07-9699-75bab10c931d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+\n",
            "|country_id|country_name|\n",
            "+----------+------------+\n",
            "|         2|         USA|\n",
            "|         3|   Australia|\n",
            "|         7|        Peru|\n",
            "|         5|       China|\n",
            "|         8|     Morocco|\n",
            "|         9|       Spain|\n",
            "+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first filter df for nov 2019\n",
        "df_filter_day = df_weather.filter(col('day').like('2019-11-%'))\n",
        "df_filter_day.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyffBPCdh_4K",
        "outputId": "720cd9ad-d7ae-4812-c1ea-e52dff2ba3c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+----------+\n",
            "|country_id|weather_state|       day|\n",
            "+----------+-------------+----------+\n",
            "|         2|           15|2019-11-01|\n",
            "|         3|           -2|2019-11-10|\n",
            "|         3|            0|2019-11-11|\n",
            "|         3|            3|2019-11-12|\n",
            "|         5|           16|2019-11-07|\n",
            "|         5|           18|2019-11-09|\n",
            "|         5|           21|2019-11-23|\n",
            "|         7|           25|2019-11-28|\n",
            "|         8|           25|2019-11-05|\n",
            "|         8|           27|2019-11-15|\n",
            "|         8|           31|2019-11-25|\n",
            "+----------+-------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# join filter day with country\n",
        "df_join = df_country.join(df_filter_day, on='country_id', how='inner')\n",
        "df_join.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxAl4FJVkKbQ",
        "outputId": "7fb71b96-1605-46af-db4c-1a9001a96aa0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+-------------+----------+\n",
            "|country_id|country_name|weather_state|       day|\n",
            "+----------+------------+-------------+----------+\n",
            "|         2|         USA|           15|2019-11-01|\n",
            "|         3|   Australia|           -2|2019-11-10|\n",
            "|         3|   Australia|            0|2019-11-11|\n",
            "|         3|   Australia|            3|2019-11-12|\n",
            "|         5|       China|           16|2019-11-07|\n",
            "|         5|       China|           18|2019-11-09|\n",
            "|         5|       China|           21|2019-11-23|\n",
            "|         7|        Peru|           25|2019-11-28|\n",
            "|         8|     Morocco|           25|2019-11-05|\n",
            "|         8|     Morocco|           27|2019-11-15|\n",
            "|         8|     Morocco|           31|2019-11-25|\n",
            "+----------+------------+-------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregate data on country_name then take average\n",
        "df_avg_temp = df_join.groupBy(col('country_name')).agg(avg('weather_state').alias('avg_temp'))\n",
        "df_avg_temp.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pElbl0u_kglg",
        "outputId": "f4d6278a-681c-49f1-f7c8-ce0f8f538e17"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------+\n",
            "|country_name|          avg_temp|\n",
            "+------------+------------------+\n",
            "|        Peru|              25.0|\n",
            "|       China|18.333333333333332|\n",
            "|     Morocco|27.666666666666668|\n",
            "|         USA|              15.0|\n",
            "|   Australia|0.3333333333333333|\n",
            "+------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use withColumn to create new col then give case statement or when otherwise\n",
        "df_final_result = df_avg_temp.withColumn('weather_type', when(col('avg_temp') <= 15 , 'Cold')\n",
        "                                      .when(col('avg_temp') >= 25 , 'Hot')\n",
        "                                      .otherwise('Warm')).select('country_name','weather_type')\n",
        "df_final_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVNeIzAGkd8U",
        "outputId": "0de46193-50dc-47e7-8a74-c902a735a821"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+\n",
            "|country_name|weather_type|\n",
            "+------------+------------+\n",
            "|        Peru|         Hot|\n",
            "|       China|        Warm|\n",
            "|     Morocco|         Hot|\n",
            "|         USA|        Cold|\n",
            "|   Australia|        Cold|\n",
            "+------------+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}